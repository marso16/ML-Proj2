{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 182] The operating system cannot run %1. Error loading \"C:\\Users\\marck\\anaconda3\\envs\\ML\\lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mall\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\fastai\\vision\\all.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mall\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\fastai\\vision\\models\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m xresnet\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unet\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\fastai\\vision\\models\\xresnet.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# AUTOGENERATED! DO NOT EDIT! File to edit: ../../../nbs/11_vision.models.xresnet.ipynb.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# %% ../../../nbs/11_vision.models.xresnet.ipynb 2\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch_basics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_state_dict_from_url\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m: \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_state_dict_from_url\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\fastai\\torch_basics.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multiprocessing\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplatform\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m platform\u001b[38;5;241m.\u001b[39msystem()\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDarwin\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Python 3.8 changed to 'spawn' but that doesn't work with PyTorch DataLoader w n_workers>0\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\torch\\__init__.py:130\u001b[0m\n\u001b[0;32m    128\u001b[0m     err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(last_error)\n\u001b[0;32m    129\u001b[0m     err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    132\u001b[0m     is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 182] The operating system cannot run %1. Error loading \"C:\\Users\\marck\\anaconda3\\envs\\ML\\lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import os \n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras \n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "dataset_path = 'dataset'\n",
    "for subfolder in tqdm(os.listdir(dataset_path)):\n",
    "    subfolder_path = os.path.join(dataset_path, subfolder)\n",
    "    for folder in os.listdir(subfolder_path):\n",
    "        subfolder_path2=os.path.join(subfolder_path,folder)\n",
    "        for image_filename in os.listdir(subfolder_path2):\n",
    "            image_path = os.path.join(subfolder_path2, image_filename)\n",
    "            images.append(image_path)\n",
    "            labels.append(folder)\n",
    "df = pd.DataFrame({'image': images, 'label': labels})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "class_counts = df['label'].value_counts()\n",
    "labels = class_counts.index\n",
    "sizes = class_counts.values\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=sns.color_palette('Set1'))\n",
    "plt.title('Distribution of Classes', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, size in zip(labels, sizes):\n",
    "    print(f\"Label: {label}, Size: {size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num=np.sort(['MildDemented','ModerateDemented','NonDemented','VeryMildDemented'])\n",
    "class_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample image for each class\n",
    "def load_and_preprocess_image(image_path, target_size=(224, 224)):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, class_name in enumerate(class_num):\n",
    "    class_images = df[df['label'] == class_name]['image'].sample(3, replace=True).tolist()\n",
    "    for j, img_path in enumerate(class_images):\n",
    "        plt.subplot(4, 3, i*3 + j + 1) \n",
    "        img = load_and_preprocess_image(img_path)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'{class_name} - Sample {j+1}')\n",
    "        plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = []\n",
    "for img in df['image']:\n",
    "    if os.path.exists(img): # Check if the file exists\n",
    "        img_shape = cv2.imread(img).shape\n",
    "        if img_shape is not None: # Check if the image was read successfully\n",
    "            sizes.append(img_shape)\n",
    "        else:\n",
    "            print(f\"Failed to read image: {img}\")\n",
    "    else:\n",
    "        print(f\"File does not exist: {img}\")\n",
    "\n",
    "sizes_df = pd.DataFrame(sizes, columns=['Height', 'Width', 'Channels'])\n",
    "\n",
    "# Convert infinite values to NaN in sizes_df as well, just in case\n",
    "sizes_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(sizes_df['Height'], kde=True, color='blue', label='Height', alpha=0.7)\n",
    "sns.histplot(sizes_df['Width'], kde=True, color='orange', label='Width', alpha=0.7)\n",
    "plt.title('Image Size Distribution')\n",
    "plt.xlabel('Size')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Size=(176,176)\n",
    "work_dr = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "# enhancing model generalization\n",
    "train_data_gen = work_dr.flow_from_dataframe(df,x_col='image',y_col='label', target_size=Size, batch_size=6500, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = train_data_gen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "train_data, train_labels = sm.fit_resample(train_data.reshape(-1, 176 * 176 * 3), train_labels)\n",
    "train_data = train_data.reshape(-1, 176,176, 3)\n",
    "print(train_data.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_labels = np.argmax(train_labels, axis=1)\n",
    "df_resampled = pd.DataFrame({'label': original_labels})\n",
    "class_counts_resampled = df_resampled['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['MildDemented','ModerateDemented','NonDemented','VeryMildDemented']\n",
    "sizes = class_counts_resampled.values\n",
    "\n",
    "assert len(labels) == len(sizes), \"Length mismatch between labels and sizes\"\n",
    "\n",
    "class_distribution_table = pd.DataFrame({'Class': labels, 'Count': sizes})\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "table = plt.table(cellText=class_distribution_table.values,\n",
    "                  colLabels=class_distribution_table.columns,\n",
    "                  cellLoc='center', loc='center', bbox=[0, 0, 1, 1])\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(1.2, 1.2) \n",
    "\n",
    "for (i, j), cell in table.get_celld().items():\n",
    "    if i == 0:\n",
    "        cell.set_text_props(fontweight='bold')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.title('Class Distribution after SMOTE', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test1, y_train, y_test1 = train_test_split(train_data,train_labels, test_size=0.3, random_state=42,shuffle=True,stratify=train_labels)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test1,y_test1, test_size=0.5, random_state=42,shuffle=True,stratify=y_test1)\n",
    "print('X_train shape is ' , X_train.shape)\n",
    "print('X_test shape is ' , X_test.shape)\n",
    "print('X_val shape is ' , X_val.shape)\n",
    "print('y_train shape is ' , y_train.shape)\n",
    "print('y_test shape is ' , y_test.shape)\n",
    "print('y_val shape is ' , y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(5):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_train[i])\n",
    "    plt.title(f'Augmented\\n{class_num[np.argmax(y_train[i])]}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.InceptionV3(input_shape=(176,176,3),include_top=False,weights='imagenet')\n",
    "base_model.trainable = False\n",
    "model_Inception=keras.models.Sequential()\n",
    "model_Inception.add(base_model)\n",
    "model_Inception.add(keras.layers.Dropout(.5))\n",
    "model_Inception.add(keras.layers.GlobalAveragePooling2D()) \n",
    "model_Inception.add(keras.layers.Flatten()) \n",
    "model_Inception.add(keras.layers.BatchNormalization())\n",
    "model_Inception.add(keras.layers.Dense(512,activation=tf.nn.relu))\n",
    "model_Inception.add(keras.layers.BatchNormalization())\n",
    "model_Inception.add(keras.layers.Dropout(.5))\n",
    "model_Inception.add(keras.layers.Dense(256,activation=tf.nn.relu))\n",
    "model_Inception.add(keras.layers.BatchNormalization())\n",
    "model_Inception.add(keras.layers.Dropout(.5))\n",
    "model_Inception.add(keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "model_Inception.add(keras.layers.BatchNormalization())\n",
    "model_Inception.add(keras.layers.Dropout(.5))\n",
    "model_Inception.add(keras.layers.Dense(64,activation=tf.nn.relu))\n",
    "model_Inception.add(keras.layers.BatchNormalization())\n",
    "model_Inception.add(keras.layers.Dropout(.5))\n",
    "model_Inception.add(keras.layers.BatchNormalization())\n",
    "model_Inception.add(keras.layers.Dense(4, activation=tf.nn.softmax))\n",
    "model_Inception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "checkpoint_cb = ModelCheckpoint(\"inception.h5\", save_best_only=True)\n",
    "early_stopping_cb = EarlyStopping(patience=4, restore_best_weights=True)\n",
    "\n",
    "optimizer_rmsprop = RMSprop(learning_rate=0.001)  # You can adjust the learning rate if needed\n",
    "model_Inception.compile(optimizer=optimizer_rmsprop, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "hist = model_Inception.fit(X_train, y_train, epochs=5, validation_data=(X_val, y_val), callbacks=[checkpoint_cb, early_stopping_cb], batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hist.history['loss'], label='Train')\n",
    "plt.plot(hist.history['val_loss'], label='Validation')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hist.history['accuracy'], label='Train')\n",
    "plt.plot(hist.history['val_accuracy'], label='Validation')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = model_Inception.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc= model_Inception.evaluate(X_test,y_test)\n",
    "print('Test Loss =', score)\n",
    "print('Test Accuracy =', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet50 approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                 get_x=ColReader('image', pref=''), \n",
    "                 get_y=ColReader('label'),\n",
    "                 splitter=RandomSplitter(),\n",
    "                 batch_tfms=[*aug_transforms(), Normalize.from_stats(*imagenet_stats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = data.dataloaders(df, bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dls.show_batch(max_n=12, nrows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = resnet50\n",
    "learn = vision_learner(dls, arch, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot_lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(50, base_lr=0.1, freeze_epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# export_path = '/kaggle/working/resnet50.pkl'\n",
    "# learn.export(export_path)\n",
    "# %cd /kaggle/working\n",
    "# from IPython.display import FileLink\n",
    "# FileLink(r'resnet50.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()\n",
    "interp.print_classification_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = learn.recorder.final_record[1]\n",
    "print(f'Final Accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 457093,
     "sourceId": 861496,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
